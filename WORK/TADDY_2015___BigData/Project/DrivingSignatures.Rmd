
num_clean_trips <- list()---
title: 'Driving Style Signatures: Who''s Behind the Steering Wheel?'
output: pdf_document
fontsize: 12
geometry: margin=0.5in
---
*(Student: Vinh Luong - 442069)*

```{r echo=FALSE}
library(knitr)
opts_chunk$set(echo = FALSE, warning=FALSE)  #cache = TRUE, 
```

``` {r message=FALSE, warning=FALSE, results='hide'}
# Set workding directory
setwd("C:/Cloud/Dropbox/MBALearnsToCode_R/WORK/TADDY_2015___BigData/Project")
superfolder_path <- "C:/Cloud/MBALearnsToCode_Data/Kaggle/AXA Driver Telematics Analysis"
data_folder_path <- "C:/Cloud/MBALearnsToCode_Data/Kaggle/AXA Driver Telematics Analysis/drivers"
source("Data_and_Features.R")
source("Visualization.R")
# Load key packages
library(data.table)
library(plyr)
library(reshape2)
library(ggplot2)
library(GGally)
library(caret)
library(gamlr)
library(randomForest)
library(lubridate)
# Start parallel computing cluster over multi cores
library(doParallel)
cl <- makePSOCKcluster(5)
clusterEvalQ(cl, library(foreach))
#registerDoParallel(cl)
#cl <- makeCluster(detectCores()-1)
registerDoParallel(cl)
getDoParWorkers()
```


# Introduction

The field of automotive insurance has a number of important questions regarding individuals' driving behaviors:

i. What data features are needed to characterize a person's driving habits? - for one thing, such features can be used to appropriately price accident risk as well as cross-sell related insurance products;

ii. In the case of an accident claim, given such data features, how well can we tell if the insured person - and not another person - is really behind the steering wheel when the incident occurs?

The advent of vehicle-mounted telematics devices has provided rich new data sources to address these issues. In this project, we attempt to develop a method to detect different people's own driving style "signatures" from a series of second-by-second GPS coordinate readings from their cars' telematics. We will show that by using just simple features such as velocity, acceleration, jerk, angular velocity and angular acceleration, we could identify with about 80% accuracy whether the insured driver is driving his/her car.


# 1. Data and Data-Preprocessing

## 1.1. Raw Data and Processed Higher-Order Features

We obtained second-by-second GPS ($x_t$, $y_t$) coordinate data from over half a million anonymized driving trips (200 trips by each of over 2,700 individual drivers) from [French insurer AXA's Kaggle competition data set](http://www.kaggle.com/c/axa-driver-telematics-analysis). This large dataset occupies nearly 6 GB of storage space when unpacked.

One trip is depicted below:

```{r}
d_1_3 <- calc_trip_data(read_driving_trip(data_folder_path, 1, 3))
plot_trip(d_1_3, 0.001, title = "Driver #1 Trip #3", color = "blue")
```

For anonymization purposes, each trip's starting point is centered at (0, 0) and the subsequent coordinates are rotated by a random angle. 

From the raw ($x_t$, $y_t$) data, we derived a number of higher-order features, measured at every second of each driving trip, as follows:

$$
\begin{aligned}
  & \textbf{\textit{x}-velocity: } \Delta x_t = x_t - x_{t - 1} \\
  & \textbf{\textit{y}-velocity: } \Delta y_t = y_t - y_{t - 1} \\
  & \textbf{absolute velocity magnitude: } v_t = \bigg\Vert \begin{array}{c}
                                                \Delta x_t \\
                                                \Delta y_t \end{array} \bigg\Vert \\
  \\
  & \textbf{\textit{x}-acceleration: } \Delta \Delta x_t = \Delta x_t - \Delta x_{t - 1} \\
  & \textbf{\textit{y}-acceleration: } \Delta \Delta y_t = \Delta y_t - \Delta y_{t - 1} \\
  & \textbf{signed acceleration magnitude: } a_t = \frac{1}{v_t} \bigg\langle \bigg[ \begin{array}{c}
                                                \Delta \Delta x_t \\
                                                \Delta \Delta y_t \end{array} \bigg],
                                          \bigg[ \begin{array}{c}
                                                \Delta x_t \\
                                                \Delta y_t \end{array} \bigg] \bigg\rangle \\
  & \text{(i.e. acceleration in the direction of the velocity vector }
    \left[ \begin{array}{c}
          \Delta x_t \\
          \Delta y_t \end{array} \right]) \\
  & \textbf{absolute acceleration magnitude: } |a_t| \\
  \\
  & \textbf{\textit{x}-jerk: } \Delta \Delta \Delta x_t = \Delta \Delta x_t - \Delta \Delta x_{t - 1} \\
  & \textbf{\textit{y}-jerk: } \Delta \Delta \Delta y_t = \Delta \Delta y_t - \Delta \Delta y_{t - 1} \\
  & \textbf{signed jerk magnitude: } j_t = \bigg\langle \bigg[ \begin{array}{c}
                                                \Delta \Delta \Delta x_t \\
                                                \Delta \Delta \Delta y_t \end{array} \bigg],
                                          \bigg[ \begin{array}{c}
                                                \Delta \Delta x_t \\
                                                \Delta \Delta y_t \end{array} \bigg] \bigg\rangle
                                          \text{ } / \text{ } \bigg\Vert \begin{array}{c}
                                                \Delta \Delta x_t \\
                                                \Delta \Delta y_t \end{array} \bigg\Vert \\
  & \text{(i.e. jerk in the direction of the acceleration vector }
    \left[ \begin{array}{c}
          \Delta \Delta x_t \\
          \Delta \Delta y_t \end{array} \right]) \\
  & \textbf{absolute jerk magnitude: } |j_t| \\
  \\
  & \textbf{angle: } \theta = \text{arctan}(\Delta y_t, \Delta x_t) \\
  & \textbf{signed angular velocity: } \Delta \theta_t = \theta_t - \theta_{t - 1} \\
  & \textbf{absolute angular velocity: } |\Delta \theta_t| \\
  & \textbf{signed angular acceleration: } \Delta \Delta \theta_t = \Delta \theta_t - \Delta \theta_{t - 1} \\
  & \textbf{absolute angular acceleration: } |\Delta \Delta \theta_t| \end{aligned}
$$

Note that because the coordinates ($x_t$, $y_t$) and the angles $\theta_t$ are already randomly shifted and rotated by the data provider, they will not be of any value in the subsequent modelling task. Only the variables signifying the *rates of change* will be considered.


## 1.2. Data Cleaning

Before we could proceed with analyzing this large data set, we had to attend to some data integrity issues. It turns out that due to lost data transmission signals and/or some extreme anonymization measures, numerous raw driving trip data sets are plagued with coordinate "jumps", i.e. missing chunks of GPS readings. One example is portrayed below:

```{r warning=FALSE}
d_1_136 <- calc_trip_data(read_driving_trip(data_folder_path, 1, 136))
plot_trip(d_1_136[241:320], 3, title = "Driver #1 Trip #136 - portion with missing data",
          color = "blue")
```

This problem is very pervasive, present data on over 40,000 driving trips by almost all of the over 2,700 drivers in the database (only eight drivers have no identified missing data).

In the above depicted case, as well as in other missing data cases, the corrupt data portions (highlighted by red dots in the plots) manifest themselves quite apparently by an unreasonably large distance from ($x_{t - 1}, y_{t - 1}$) to ($x_t, y_t$), or equivalently an unreasonably high velocity $v_t$ estimated from such consecutive pairs of coordinates. We hence devised a method to detect and interpolate the missing data, described at a high level as follows:

* detect data rows with derived velocity $v_t$ > 36 meters/second, which is approximately 80 miles/hour, the upper bound of the [U.S. speed limits](http://en.wikipedia.org/wiki/Speed_limits_in_the_United_States_by_jurisdiction), or, equivalently, 130 kilometers/hour, the upper bound of the [European speed limits](http://www.theaa.ie/AA/Motoring-advice/Driving-in-Europe/Speed-Limits.aspx) *(when one's car has a telematics device mounted, one should be quite properly incentivized not to speed!)*;

* look at time windows of 3 seconds before and 3 seconds after each of such instance, and estimate the average velocities $v_\text{before}$ and $v_\text{after}$ and angular directions $\theta_\text{before}$ and $\theta_\text{after}$;

* by certain polygonal approximations, estimate the length of one or several smooth parabolic arcs spanning the locations ($x_\text{before}$, $y_\text{before}$) and ($x_\text{after}$, $y_\text{after}$) and with tangents at angles $\theta_\text{before}$ and $\theta_\text{after}$ at those points *(it will become apparent in certain visualizations below why parabolic curves are more natural than straight lines or circular curves)*;

* estimate the number of seconds the vehicle needs to take to traverse such parabolic arc(s) at velocity $v_\text{mean} = \frac{1}{2}(v_\text{before} + v_\text{after})$; and

* interpolate missing intermediate locations along the parabolic arc(s), with certain technical adjustments to make the vehicle accelerate or decelerate evenly from $v_\text{before}$ to $v_\text{after}$.

With such a data interpolation method, the above case of Driver #1's Trip #136 could be corrected to the following:

```{r}
d_1_136_corrected <- clean_velocity_data(d_1_136)
p1 <- plot_trip(d_1_136[241:320], 3, title = "Dr#1 Tr#136 - missing data",
          color = "blue")
p2 <- plot_trip(d_1_136_corrected[241:350], 3, title = "Dr#1 Tr#136 - interpolated",
          color = "blue")
multiplot(p1, p2, cols = 2)
```

Below are several other examples demonstrating the efficacy of this method in recovering smooth, realistic-looking paths to replace missing data. Notice how parabolic-curve approximation works really well, while using straight lines or circular arcs would have created much less believable trajectories.  

```{r}
d_1_83 <- calc_trip_data(read_driving_trip(data_folder_path, 1, 83))
d_1_83_corrected <- clean_velocity_data(d_1_83)
p1 <- plot_trip(d_1_83[261:300], 1.3, title = "Dr#1 Tr#83 - missing data",
          color = "blue")
p2 <- plot_trip(d_1_83_corrected[261 : 330], 1.3, title = "Dr#1 Tr#83 - interpolated",
          color = "blue")
multiplot(p1, p2, cols = 2)
```

```{r}
d_3000_21 <- calc_trip_data(read_driving_trip(data_folder_path, 3000, 21))
d_3000_21_corrected <- clean_velocity_data(d_3000_21)
p1 <- plot_trip(d_3000_21[261 : 500], 1, title = "Dr#3000 Tr#21 - missing data",
          color = "blue")
p2 <- plot_trip(d_3000_21_corrected[261 : 1150], 1, title = "Dr#3000 Tr#21 - interpolated",
          color = "blue")
multiplot(p1, p2, cols = 2)
```

```{r}
d_20_170 <- calc_trip_data(read_driving_trip(data_folder_path, 20, 170))
d_20_170_corrected <- clean_velocity_data(d_20_170)
p1 <- plot_trip(d_20_170[701 : 890], 1, title = "Dr#20 Tr#170 - missing data",
          color = "blue")
p2 <- plot_trip(d_20_170_corrected[701 : 1600], 1, title = "Dr#20 Tr#170 - interpolated",
          color = "blue")
multiplot(p1, p2, cols = 2)
```

However, there are also many cases with data so corrupt that they cannot be reliably recovered:

```{r}
d_20_13 <- calc_trip_data(read_driving_trip(data_folder_path, 20, 13))
d_20_13_corrected <- clean_velocity_data(d_20_13)
p1 <- plot_trip(d_20_13, 1.3, title = "Dr#20 Tr#13 - very corrupt data",
          color = "blue")
p2 <- plot_trip(d_20_13_corrected, 1.3, title = "Dr#20 Tr#13 - interpolated",
          color = "blue")
multiplot(p1, p2, cols = 2)
```

We hence decided to limit recovery of missing data to cases with three or fewer missing sections, and discard the more seriously impaired cases. Overall, we recovered missing data for nearly 33,000 out of the 40,000 affected driving trip data sets.

Additionally, we removed rows of data with:

* velocities $v_t$ < 2 meters/second (about 4-5 miles/hour), because below that threshold cars are not meaningfully moving; and/or

* absolute angular velocities $|\Delta \theta_t|$ > 150 degrees, because such turns are too sharp for cars to reasonably perform in one second

In terms of time cost, our various data verification and cleaning steps took us about 100 hours on a single computer running on seven cores.


# 2. Driver Identification as Classification Problem

Following the above data verification and cleaning procedures, the question for us to address now is that, with such a database of labeled personal driving trip data (raw GPS plus derived features), whether we can effectively distinguish among different drivers' different driving styles.


## 2.1. Problem Framing

For each individual Driver *D*, we have got a collection of labeled driving trips representing his/her typical driving habits. Because we have over 2,700 such drivers in the database, for each Driver *D* we have also got an abundance of labeled driving trips that are ***not*** by Driver *D*.

With such labeled data and a "one-vs.-all" approach, we can train a discriminative classification model to distinguish the driving style of Driver *D* versus those of other drivers. At test time, the trained discriminative model will be given an unlabeled driving trip data set comprising GPS coordinate readings and the related derived higher-order features, and the model will be evaluated according to how well it classifies whether or not the trip is by Driver *D*.


## 2.2. 

These features are . Among them, we will focus on several features measuring **rates of change**, namely **velocity**, **acceleration**, **(signed and absolute) angular velocity** and **(signed and absolute) angular acceleration**. For the above depicted trip, the distributions and correlations among these variables are as follows:

```{r}
#unclean <- clean_velocity_data_for_all_driver_trips(superfolder_path)

#unclean <- readRDS(file.path(superfolder_path, "unclean_velocity_data_cases.RDS"))
#drivers <- list_drivers(data_folder_path)
#num_drivers <- length(drivers)
#drivers_modelled <- readRDS("./modelling_cache/drivers_modelled.RDS")
#for (i in 1 : num_drivers) {
#  driver <- drivers[i]
#  if (!(driver %in% drivers_modelled)) {
#    cat("Modelling Driver #", driver, "... ", sep = "")
#    model_data <- build_one_vs_all_data_sets(driver, data_folder_path, unclean)
#    train_data <- copy(model_data$train)
#    random_forest <-
#      randomForest(x = train_data[, .(velocity, acceleration, abs_acceleration, jerk, abs_jerk,
#                                  angular_velocity, abs_angular_velocity,
#                                  angular_acceleration, abs_angular_acceleration)],
#                   y = train_data$driver_class)
#    test <- predict_driver(random_forest, copy(model_data$test), model_data$test_indices)
#    saveRDS(test, paste("./modelling_cache/driver_", driver, ".RDS", sep = ""))
#    drivers_modelled <- append(drivers_modelled, driver)
#    saveRDS(drivers_modelled, "./modelling_cache/drivers_modelled.RDS")
    
#    num_true_pos <- sum(test$true_pos, na.rm = TRUE)
#    accuracy <- formatC(100 * (num_true_pos + sum(test$true_neg, na.rm = TRUE)) / nrow(test),
#                        format = "f", digits = 1)
#    precision <- formatC(100 * num_true_pos / sum(test$pred_pos, na.rm = TRUE), format = "f", digits = 1)
#    recall <- formatC(100 * num_true_pos / sum(test$pos, na.rm = TRUE), format = "f", digits = 1)
#    cat("accuracy = ", accuracy, "%, precision = ", precision, "%, recall = ", recall, "%\n",
#        sep = "")
#  }
#}



```

```{r echo=FALSE}
stopCluster(cl)
```